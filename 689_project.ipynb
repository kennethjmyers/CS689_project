{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat\n",
      "[y = 4, x = 2]\n"
     ]
    }
   ],
   "source": [
    "from z3 import *\n",
    "\n",
    "x = Real('x')\n",
    "y = Real('y')\n",
    "s = Solver()\n",
    "s.add(x + y > 5, x > 1, y > 1)\n",
    "print(s.check())\n",
    "print(s.model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "housing_data = pd.read_csv('./Data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_cols = [i for i in housing_data.columns if 'sqft' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sqft_living  sqft_lot  sqft_above  sqft_basement  sqft_living15  sqft_lot15\n",
       "0         1180      5650        1180              0           1340        5650\n",
       "1         2570      7242        2170            400           1690        7639\n",
       "2          770     10000         770              0           2720        8062\n",
       "3         1960      5000        1050            910           1360        5000\n",
       "4         1680      8080        1680              0           1800        7503"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_data[sqft_cols]\n",
    "y = housing_data['price']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "# from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=50  # number of trees\n",
    ")\n",
    "\n",
    "gbr.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Tree in module sklearn.tree._tree:\n",
      "\n",
      "class Tree(builtins.object)\n",
      " |  Array-based representation of a binary decision tree.\n",
      " |  \n",
      " |  The binary tree is represented as a number of parallel arrays. The i-th\n",
      " |  element of each array holds information about the node `i`. Node 0 is the\n",
      " |  tree's root. You can find a detailed description of all arrays in\n",
      " |  `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
      " |  nodes, resp. In this case the values of nodes of the other type are\n",
      " |  arbitrary!\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_count : int\n",
      " |      The number of nodes (internal nodes + leaves) in the tree.\n",
      " |  \n",
      " |  capacity : int\n",
      " |      The current capacity (i.e., size) of the arrays, which is at least as\n",
      " |      great as `node_count`.\n",
      " |  \n",
      " |  max_depth : int\n",
      " |      The depth of the tree, i.e. the maximum depth of its leaves.\n",
      " |  \n",
      " |  children_left : array of int, shape [node_count]\n",
      " |      children_left[i] holds the node id of the left child of node i.\n",
      " |      For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
      " |      children_left[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] <= threshold[i].\n",
      " |  \n",
      " |  children_right : array of int, shape [node_count]\n",
      " |      children_right[i] holds the node id of the right child of node i.\n",
      " |      For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
      " |      children_right[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] > threshold[i].\n",
      " |  \n",
      " |  feature : array of int, shape [node_count]\n",
      " |      feature[i] holds the feature to split on, for the internal node i.\n",
      " |  \n",
      " |  threshold : array of double, shape [node_count]\n",
      " |      threshold[i] holds the threshold for the internal node i.\n",
      " |  \n",
      " |  value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
      " |      Contains the constant prediction value of each node.\n",
      " |  \n",
      " |  impurity : array of double, shape [node_count]\n",
      " |      impurity[i] holds the impurity (i.e., the value of the splitting\n",
      " |      criterion) at node i.\n",
      " |  \n",
      " |  n_node_samples : array of int, shape [node_count]\n",
      " |      n_node_samples[i] holds the number of training samples reaching node i.\n",
      " |  \n",
      " |  weighted_n_node_samples : array of int, shape [node_count]\n",
      " |      weighted_n_node_samples[i] holds the weighted number of training samples\n",
      " |      reaching node i.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |      Getstate re-implementation, for pickling.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Reduce re-implementation, for pickling.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |      Setstate re-implementation, for unpickling.\n",
      " |  \n",
      " |  apply(...)\n",
      " |      Finds the terminal region (=leaf node) for each sample in X.\n",
      " |  \n",
      " |  compute_feature_importances(...)\n",
      " |      Computes the importance of each feature (aka variable).\n",
      " |  \n",
      " |  compute_partial_dependence(...)\n",
      " |      Partial dependence of the response on the ``target_feature`` set.\n",
      " |      \n",
      " |      For each sample in ``X`` a tree traversal is performed.\n",
      " |      Each traversal starts from the root with weight 1.0.\n",
      " |      \n",
      " |      At each non-leaf node that splits on a target feature, either\n",
      " |      the left child or the right child is visited based on the feature\n",
      " |      value of the current sample, and the weight is not modified.\n",
      " |      At each non-leaf node that splits on a complementary feature,\n",
      " |      both children are visited and the weight is multiplied by the fraction\n",
      " |      of training samples which went to each child.\n",
      " |      \n",
      " |      At each leaf, the value of the node is multiplied by the current\n",
      " |      weight (weights sum to 1 for all visited terminal nodes).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : view on 2d ndarray, shape (n_samples, n_target_features)\n",
      " |          The grid points on which the partial dependence should be\n",
      " |          evaluated.\n",
      " |      target_features : view on 1d ndarray, shape (n_target_features)\n",
      " |          The set of target features for which the partial dependence\n",
      " |          should be evaluated.\n",
      " |      out : view on 1d ndarray, shape (n_samples)\n",
      " |          The value of the partial dependence function on each grid\n",
      " |          point.\n",
      " |  \n",
      " |  decision_path(...)\n",
      " |      Finds the decision path (=node) for each sample in X.\n",
      " |  \n",
      " |  predict(...)\n",
      " |      Predict target for X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  capacity\n",
      " |  \n",
      " |  children_left\n",
      " |  \n",
      " |  children_right\n",
      " |  \n",
      " |  feature\n",
      " |  \n",
      " |  impurity\n",
      " |  \n",
      " |  max_depth\n",
      " |  \n",
      " |  max_n_classes\n",
      " |  \n",
      " |  n_classes\n",
      " |  \n",
      " |  n_features\n",
      " |  \n",
      " |  n_leaves\n",
      " |  \n",
      " |  n_node_samples\n",
      " |  \n",
      " |  n_outputs\n",
      " |  \n",
      " |  node_count\n",
      " |  \n",
      " |  threshold\n",
      " |  \n",
      " |  value\n",
      " |  \n",
      " |  weighted_n_node_samples\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "help(sklearn.tree._tree.Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = gbr.estimators_[0,0].tree_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = gbr.estimators_[0,0].tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, -191935.98367101545] And(x_0_i <= 3406.0, x_0_i <= 2259.5, x_0_i <= 1529.0, wl=-191935.98367101545)\n",
      "[1, 2, 4, -84004.33994787265] And(x_0_i <= 3406.0, x_0_i <= 2259.5, x_0_i > 1529.0, wl=-84004.33994787265)\n",
      "[1, 5, 6, 74673.34801182243] And(x_0_i <= 3406.0, x_0_i > 2259.5, x_4_i <= 2855.0, wl=74673.34801182243)\n",
      "[1, 5, 7, 281749.63687257515] And(x_0_i <= 3406.0, x_0_i > 2259.5, x_4_i > 2855.0, wl=281749.63687257515)\n",
      "[8, 9, 10, 452079.9962296856] And(x_0_i > 3406.0, x_0_i <= 4755.0, x_0_i <= 4062.5, wl=452079.9962296856)\n",
      "[8, 9, 11, 787092.8382778168] And(x_0_i > 3406.0, x_0_i <= 4755.0, x_0_i > 4062.5, wl=787092.8382778168)\n",
      "[8, 12, 13, 1306390.799409939] And(x_0_i > 3406.0, x_0_i > 4755.0, x_0_i <= 7940.0, wl=1306390.799409939)\n",
      "[8, 12, 14, 4541341.85823347] And(x_0_i > 3406.0, x_0_i > 4755.0, x_0_i > 7940.0, wl=4541341.85823347)\n",
      "\n",
      "Tree Representation:\n",
      " Or(\n",
      "\tAnd(x_0_i <= 3406.0, x_0_i <= 2259.5, x_0_i <= 1529.0, wl=-191935.98367101545),\n",
      "\tAnd(x_0_i <= 3406.0, x_0_i <= 2259.5, x_0_i > 1529.0, wl=-84004.33994787265),\n",
      "\tAnd(x_0_i <= 3406.0, x_0_i > 2259.5, x_4_i <= 2855.0, wl=74673.34801182243),\n",
      "\tAnd(x_0_i <= 3406.0, x_0_i > 2259.5, x_4_i > 2855.0, wl=281749.63687257515),\n",
      "\tAnd(x_0_i > 3406.0, x_0_i <= 4755.0, x_0_i <= 4062.5, wl=452079.9962296856),\n",
      "\tAnd(x_0_i > 3406.0, x_0_i <= 4755.0, x_0_i > 4062.5, wl=787092.8382778168),\n",
      "\tAnd(x_0_i > 3406.0, x_0_i > 4755.0, x_0_i <= 7940.0, wl=1306390.799409939),\n",
      "\tAnd(x_0_i > 3406.0, x_0_i > 4755.0, x_0_i > 7940.0, wl=4541341.85823347)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# do this just for regression to start\n",
    "\n",
    "##### HOW TO GENERATE LOGICAL REPRESENTATIONS\n",
    "\n",
    "### Leaf encoding\n",
    "# run a DFS on the tree, store nodes in a stack\n",
    "\n",
    "# when you reach a leaf, write the logical statements for \n",
    "# pi(l) which is stack[1:] n wl where wl is the weight value of the leaf\n",
    "\n",
    "paths = []\n",
    "pi_l = []  # this will be a list of lists of every pi_l ie: ['xi_1 <= 1000', 'xi_2 > 6000'..., wl]\n",
    "stack=[0]  # initialize stack for tree\n",
    "pi_l_stack=[]  # a stack for holding pi_l definitions based on position in tree\n",
    "n_nodes = tree.node_count\n",
    "threshold = tree.threshold \n",
    "feature = tree.feature\n",
    "left_searched = [False for _ in range(n_nodes)]\n",
    "right_searched = [False for _ in range(n_nodes)]\n",
    "children_left = tree.children_left\n",
    "children_right = tree.children_right\n",
    "values = tree.value  # I think these are the average value (or something) of a node based on training data\n",
    "\n",
    "# DFS\n",
    "while True:\n",
    "    this_node = stack[-1]\n",
    "    this_threshold = threshold[this_node]\n",
    "    this_feature = feature[this_node]\n",
    "    \n",
    "    searched_left_already = left_searched[this_node]\n",
    "    searched_right_already = right_searched[this_node]\n",
    "    if searched_left_already and searched_right_already:\n",
    "        stack.pop(-1)  # pop the last node off of the stack so we go one level up on the next run\n",
    "        pi_l_stack.pop(-1)\n",
    "        continue\n",
    "        \n",
    "    if not searched_left_already:  # search the left_child\n",
    "        child = children_left[this_node]\n",
    "        this_op = f'x_{this_feature}_i <= {this_threshold}'  # I wasn't sure exactly how these should be defined\n",
    "        left_searched[this_node]=True\n",
    "    else:  # search the right child\n",
    "        child = children_right[this_node]\n",
    "        this_op = f'x_{this_feature}_i > {this_threshold}'\n",
    "        right_searched[this_node]=True\n",
    "        \n",
    "    if child==-1:  # at leaf\n",
    "        # append path to this node + the value of this node\n",
    "        this_path = deepcopy(stack[1:])+[deepcopy(values[this_node][0,0])]\n",
    "        this_pi_l = deepcopy(pi_l_stack[:])+['wl='+deepcopy(str(values[this_node][0,0]))]\n",
    "        paths.append(this_path)\n",
    "        pi_l.append(this_pi_l)\n",
    "        result='And('+', '.join(this_pi_l)+')'\n",
    "        print(this_path, result)\n",
    "        \n",
    "        if this_node == n_nodes-1:\n",
    "            break  # we have searched all paths and can break\n",
    "        stack.pop(-1)  # pop the last node off of the stack so we go one level up on the next run\n",
    "        pi_l_stack.pop(-1)\n",
    "    else:  # not at leaf\n",
    "        # append the child to the stack and continue search\n",
    "        stack.append(child)     \n",
    "        pi_l_stack.append(this_op)\n",
    "\n",
    "# pruning: using an input x_i', compare the difference at every node in the DFS x_i\n",
    "# if |x_i-x_i'| < epsilon where epsilon is the predefined robustness factor\n",
    "# then keep node, otherwise pop current node from the stack and \n",
    "# stop searching this branch of the tree (return to previous level)\n",
    "\n",
    "### Tree encoding\n",
    "# then represent PI(D) as V(pi(l)) a disjunction of all pi(l) found during DFS\n",
    "PI_D = 'Or(\\n\\t'+',\\n\\t'.join(['And('+', '.join(this_pi_l)+')' for this_pi_l in pi_l])+'\\n)'\n",
    "print('\\nTree Representation:\\n',PI_D)\n",
    "### GBM encoding\n",
    "# lastly encode the full model instelf, (n(PI(D_i))) n (out=sum(wl_i))\n",
    "# I haven't fulling figured out how to represent the out=sum(wl_i) part yet.\n",
    "# wl_i should be the one value returned from each tree PI(D_i), we might just \n",
    "# need the additional predicate D_i(x)=wl_i meaning that putting x into the decision tree returns wl_i\n",
    "# but I'm not totally sure how this is expressed for Z3\n",
    "\n",
    "### Robust property encoding\n",
    "# see section 5 of the paper this is easier than the previous stuff but it \n",
    "# again has stuff like R(x) that I need to read the documentation on how to define\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-84004.33994787265"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.value[4][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3, -1, -1,  6, -1, -1,  9, 10, -1, -1, 13, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.children_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5,  4, -1, -1,  7, -1, -1, 12, 11, -1, -1, 14, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.children_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x20e002c59d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
